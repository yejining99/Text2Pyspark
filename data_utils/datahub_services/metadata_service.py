"""
DataHub ë©”íƒ€ë°ì´í„° ì„œë¹„ìŠ¤ ëª¨ë“ˆ

í…Œì´ë¸” ë©”íƒ€ë°ì´í„°, ë¦¬ë‹ˆì§€, URN ê´€ë ¨ ê¸°ëŠ¥ì„ ì œê³µí•©ë‹ˆë‹¤.
"""

from datahub.metadata.schema_classes import (
    DatasetPropertiesClass,
    SchemaMetadataClass,
    UpstreamLineageClass,
)
from datahub.ingestion.graph.client import DatahubClientConfig, DataHubGraph
from collections import defaultdict

from data_utils.datahub_services.base_client import DataHubBaseClient


class MetadataService:
    """ë©”íƒ€ë°ì´í„° ê´€ë ¨ ì„œë¹„ìŠ¤ í´ë˜ìŠ¤"""

    def __init__(self, client: DataHubBaseClient):
        """
        ë©”íƒ€ë°ì´í„° ì„œë¹„ìŠ¤ ì´ˆê¸°í™”

        Args:
            client (DataHubBaseClient): DataHub ê¸°ë³¸ í´ë¼ì´ì–¸íŠ¸
        """
        self.client = client
        self.datahub_graph = client.get_datahub_graph()
        self.gms_server = client.gms_server

    def get_table_name(self, urn):
        """URNì— ëŒ€í•œ í…Œì´ë¸” ì´ë¦„ ê°€ì ¸ì˜¤ê¸°"""
        dataset_properties = self.datahub_graph.get_aspect(
            urn, aspect_type=DatasetPropertiesClass
        )
        if dataset_properties:
            database_info = dataset_properties.get("customProperties", {}).get(
                "dbt_unique_id", ""
            )
            if database_info:
                database_info = database_info.split(".")[-2]
            else:
                database_info = ""
            table_info = dataset_properties.get("name", None)
            return database_info + "." + table_info
        return None

    def get_table_description(self, urn):
        """URNì— ëŒ€í•œ í…Œì´ë¸” ì„¤ëª… ê°€ì ¸ì˜¤ê¸°"""
        dataset_properties = self.datahub_graph.get_aspect(
            urn, aspect_type=DatasetPropertiesClass
        )
        if dataset_properties:
            return dataset_properties.get("description", None)
        return None

    def get_column_names_and_descriptions(self, urn):
        """URNì— ëŒ€í•œ ì»¬ëŸ¼ ì´ë¦„ ë° ì„¤ëª… ê°€ì ¸ì˜¤ê¸°"""
        schema_metadata = self.datahub_graph.get_aspect(
            urn, aspect_type=SchemaMetadataClass
        )
        columns = []
        if schema_metadata:
            for field in schema_metadata.fields:
                # nativeDataTypeê°€ ì—†ê±°ë‚˜ ë¹ˆ ë¬¸ìì—´ì¸ ê²½ìš° None ì²˜ë¦¬
                native_type = getattr(field, "nativeDataType", None)
                column_type = (
                    native_type if native_type and native_type.strip() else None
                )

                columns.append(
                    {
                        "column_name": field.fieldPath,
                        "column_description": field.description,
                        "column_type": column_type,
                    }
                )
        return columns

    def get_table_lineage(
        self,
        urn,
        counts=100,
        direction="DOWNSTREAM",
        degree_values=None,
    ):
        """URNì— ëŒ€í•œ DOWNSTREAM/UPSTREAM lineage entityë¥¼ counts ë§Œí¼ ê°€ì ¸ì˜¤ëŠ” í•¨ìˆ˜"""
        if degree_values is None:
            degree_values = ["1", "2"]

        graph = DataHubGraph(DatahubClientConfig(server=self.gms_server))

        query = """
            query scrollAcrossLineage($input: ScrollAcrossLineageInput!) {
            scrollAcrossLineage(input: $input) {
                searchResults {
                    degree
                    entity {
                        urn
                        type
                    }
                }
            }
        }
        """
        variables = {
            "input": {
                "query": "*",
                "urn": urn,
                "count": counts,
                "direction": direction,
                "orFilters": [
                    {
                        "and": [
                            {
                                "condition": "EQUAL",
                                "negated": "false",
                                "field": "degree",
                                "values": degree_values,
                            }
                        ]
                    }
                ],
            }
        }

        result = graph.execute_graphql(query=query, variables=variables)
        return urn, result

    def get_column_lineage(self, urn):
        """URNì— ëŒ€í•œ UPSTREAM lineageì˜ column sourceë¥¼ ê°€ì ¸ì˜¤ëŠ” í•¨ìˆ˜"""
        # DataHub ì—°ê²° ë° lineage ê°€ì ¸ì˜¤ê¸°
        graph = DataHubGraph(DatahubClientConfig(server=self.gms_server))
        result = graph.get_aspect(entity_urn=urn, aspect_type=UpstreamLineageClass)

        # downstream dataset (URN í…Œì´ë¸”ëª…) íŒŒì‹±
        try:
            down_dataset = urn.split(",")[1]
            table_name = down_dataset.split(".")[1]
        except IndexError:
            # URNì´ ìœ íš¨í•˜ì§€ ì•ŠëŠ” ê²½ìš°
            print(f"[ERROR] Invalid URN format: {urn}")
            return {}

        # upstream_datasetë³„ë¡œ column lineage
        upstream_map = defaultdict(list)

        if not result:
            return {"downstream_dataset": table_name, "lineage_by_upstream_dataset": []}

        for fg in result.fineGrainedLineages or []:
            confidence_score = (
                fg.confidenceScore if fg.confidenceScore is not None else 1.0
            )
            for down in fg.downstreams:
                down_column = down.split(",")[-1].replace(")", "")
                for up in fg.upstreams:
                    up_dataset = up.split(",")[1]
                    up_dataset = up_dataset.split(".")[1]
                    up_column = up.split(",")[-1].replace(")", "")

                    upstream_map[up_dataset].append(
                        {
                            "upstream_column": up_column,
                            "downstream_column": down_column,
                            "confidence": confidence_score,
                        }
                    )

        # ìµœì¢… ê²°ê³¼ êµ¬ì¡° ìƒì„±
        parsed_lineage = {
            "downstream_dataset": table_name,
            "lineage_by_upstream_dataset": [],
        }

        for up_dataset, column_mappings in upstream_map.items():
            parsed_lineage["lineage_by_upstream_dataset"].append(
                {"upstream_dataset": up_dataset, "columns": column_mappings}
            )

        return parsed_lineage

    def min_degree_lineage(self, lineage_result):
        """lineage ì¤‘ ìµœì†Œ degreeë§Œ ê°€ì ¸ì˜¤ëŠ” í•¨ìˆ˜"""
        table_degrees = {}
        urn, lineage_data = lineage_result

        for item in lineage_data["scrollAcrossLineage"]["searchResults"]:
            table = item["entity"]["urn"].split(",")[1]
            table_name = table.split(".")[1]
            degree = item["degree"]
            table_degrees[table_name] = min(
                degree, table_degrees.get(table_name, float("inf"))
            )

        return table_degrees

    def build_table_metadata(self, urn, max_degree=2, sort_by_degree=True):
        """í…Œì´ë¸” ë‹¨ìœ„ë¡œ í…Œì´ë¸” ì´ë¦„, ì„¤ëª…, ì»¬ëŸ¼, í…Œì´ë¸” ë³„ ë¦¬ë‹ˆì§€(downstream/upstream), ì»¬ëŸ¼ ë³„ ë¦¬ë‹ˆì§€(upstream)ì´ í¬í•¨ëœ ë©”íƒ€ë°ì´í„° ìƒì„± í•¨ìˆ˜"""
        metadata = {
            "table_name": self.get_table_name(urn),
            "description": self.get_table_description(urn),
            "columns": self.get_column_names_and_descriptions(urn),
            "lineage": {},
        }

        def process_lineage(direction):
            # direction : DOWNSTREAM/UPSTREAM ë³„ë¡œ degreeê°€ ìµœì†Œì¸ lineageë¥¼ ê°€ì ¸ì˜¤ëŠ” í•¨ìˆ˜
            # í…Œì´ë¸” lineage ê°€ì ¸ì˜¤ê¸°
            lineage_result = self.get_table_lineage(urn, direction=direction)
            table_degrees = self.min_degree_lineage(lineage_result)
            current_table_name = metadata["table_name"]

            # degree í•„í„°ë§
            filtered_lineage = [
                {"table": table, "degree": degree}
                for table, degree in table_degrees.items()
                if degree <= max_degree and table != current_table_name
            ]

            # degree ê¸°ì¤€ ì •ë ¬
            if sort_by_degree:
                filtered_lineage.sort(key=lambda x: x["degree"])

            return filtered_lineage

        # DOWNSTREAM / UPSTREAM ë§í¬ ì¶”ê°€
        metadata["lineage"]["downstream"] = process_lineage("DOWNSTREAM")
        metadata["lineage"]["upstream"] = process_lineage("UPSTREAM")

        # ì»¬ëŸ¼ ë‹¨ìœ„ lineage ì¶”ê°€
        column_lineage = self.get_column_lineage(urn)
        metadata["lineage"]["upstream_columns"] = column_lineage.get(
            "lineage_by_upstream_dataset", []
        )

        return metadata

    def get_urn_info(self, urn):
        """
        íŠ¹ì • URNì— ëŒ€í•œ ëª¨ë“  ê´€ë ¨ ì •ë³´ë¥¼ ê°€ì ¸ì˜¤ëŠ” í•¨ìˆ˜

        Args:
            urn (str): ì¡°íšŒí•  ë°ì´í„°ì…‹ URN

        Returns:
            dict: URNì— ëŒ€í•œ ì „ì²´ ë©”íƒ€ë°ì´í„° ì •ë³´
        """
        print(f"\n=== URN ì •ë³´ ì¡°íšŒ: {urn} ===\n")

        try:
            # ê¸°ë³¸ í…Œì´ë¸” ë©”íƒ€ë°ì´í„° ê°€ì ¸ì˜¤ê¸°
            metadata = self.build_table_metadata(urn)

            # ê²°ê³¼ ì¶œë ¥
            self._print_urn_details(metadata)

            return metadata

        except Exception as e:
            error_msg = f"URN ì •ë³´ ì¡°íšŒ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}"
            print(error_msg)
            return {"error": True, "message": error_msg}

    def _print_urn_details(self, metadata):
        """URN ë©”íƒ€ë°ì´í„°ë¥¼ ë³´ê¸° ì¢‹ê²Œ ì¶œë ¥í•˜ëŠ” ë‚´ë¶€ í•¨ìˆ˜"""

        # í…Œì´ë¸” ê¸°ë³¸ ì •ë³´
        print("ğŸ“‹ í…Œì´ë¸” ì •ë³´:")
        print(f"  ì´ë¦„: {metadata.get('table_name', 'N/A')}")
        print(f"  ì„¤ëª…: {metadata.get('description', 'N/A')}\n")

        # ì»¬ëŸ¼ ì •ë³´
        columns = metadata.get("columns", [])
        if columns:
            print(f"ğŸ“Š ì»¬ëŸ¼ ì •ë³´ ({len(columns)}ê°œ):")
            for i, col in enumerate(columns, 1):
                print(f"  {i}. {col['column_name']} ({col.get('column_type', 'N/A')})")
                if col.get("column_description"):
                    print(f"     â†’ {col['column_description']}")
            print()

        # ë¦¬ë‹ˆì§€ ì •ë³´
        lineage = metadata.get("lineage", {})

        # Downstream í…Œì´ë¸”
        downstream = lineage.get("downstream", [])
        if downstream:
            print(f"â¬‡ï¸ Downstream í…Œì´ë¸” ({len(downstream)}ê°œ):")
            for table in downstream:
                print(f"  - {table['table']} (degree: {table['degree']})")
            print()

        # Upstream í…Œì´ë¸”
        upstream = lineage.get("upstream", [])
        if upstream:
            print(f"â¬†ï¸ Upstream í…Œì´ë¸” ({len(upstream)}ê°œ):")
            for table in upstream:
                print(f"  - {table['table']} (degree: {table['degree']})")
            print()

        # ì»¬ëŸ¼ ë ˆë²¨ ë¦¬ë‹ˆì§€
        upstream_columns = lineage.get("upstream_columns", [])
        if upstream_columns:
            print("ğŸ”— ì»¬ëŸ¼ ë ˆë²¨ ë¦¬ë‹ˆì§€:")
            for upstream_dataset in upstream_columns:
                dataset_name = upstream_dataset["upstream_dataset"]
                columns = upstream_dataset["columns"]
                print(f"  ğŸ“‹ {dataset_name}:")
                for col in columns:
                    confidence = col.get("confidence", 1.0)
                    print(
                        f"    {col['upstream_column']} â†’ {col['downstream_column']} (ì‹ ë¢°ë„: {confidence})"
                    )
            print()
