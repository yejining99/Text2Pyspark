from datahub.metadata.schema_classes import DatasetPropertiesClass, SchemaMetadataClass
from datahub.emitter.rest_emitter import DatahubRestEmitter
from datahub.ingestion.graph.client import DatahubClientConfig, DataHubGraph
from datahub.metadata.schema_classes import UpstreamLineageClass
from collections import defaultdict
import requests
from data_utils.queries import (
    ROOT_GLOSSARY_NODES_QUERY,
    GLOSSARY_NODE_QUERY,
    LIST_QUERIES_QUERY,
    QUERIES_BY_URN_QUERY,
    GLOSSARY_TERMS_BY_URN_QUERY,
)


class DatahubMetadataFetcher:
    def __init__(self, gms_server="http://localhost:8080", extra_headers={}):
        # gms_server ì£¼ì†Œ ìœ íš¨ì„± ê²€ì‚¬
        if not self._is_valid_gms_server(gms_server):
            raise ValueError(f"ìœ íš¨í•˜ì§€ ì•Šì€ GMS ì„œë²„ ì£¼ì†Œ: {gms_server}")

        self.emitter = DatahubRestEmitter(
            gms_server=gms_server, extra_headers=extra_headers
        )
        self.datahub_graph = self.emitter.to_graph()
        self.gms_server = gms_server

    def _is_valid_gms_server(self, gms_server):
        # GMS ì„œë²„ ì£¼ì†Œì˜ ìœ íš¨ì„±ì„ ê²€ì‚¬í•˜ëŠ” ë¡œì§ ì¶”ê°€
        # GraphQL ìš”ì²­ì„ ì‚¬ìš©í•˜ì—¬ ì„œë²„ ìƒíƒœ í™•ì¸
        query = {"query": "{ health { status } }"}
        headers = {"Content-Type": "application/json"}

        try:
            response = requests.post(
                f"{gms_server}/api/graphql", json=query, headers=headers
            )
            return response.status_code == 200
        except requests.exceptions.RequestException:
            return False

    def get_urns(self):
        # í•„í„°ë¥¼ ì ìš©í•˜ì—¬ ë°ì´í„°ì…‹ì˜ URN ê°€ì ¸ì˜¤ê¸°
        return self.datahub_graph.get_urns_by_filter()

    def get_table_name(self, urn):
        # URNì— ëŒ€í•œ í…Œì´ë¸” ì´ë¦„ ê°€ì ¸ì˜¤ê¸°
        dataset_properties = self.datahub_graph.get_aspect(
            urn, aspect_type=DatasetPropertiesClass
        )
        if dataset_properties:
            database_info = dataset_properties.get("customProperties", {}).get(
                "dbt_unique_id", ""
            )
            if database_info:
                database_info = database_info.split(".")[-2]
            else:
                database_info = ""
            table_info = dataset_properties.get("name", None)
            return database_info + "." + table_info
        return None

    def get_table_description(self, urn):
        # URNì— ëŒ€í•œ í…Œì´ë¸” ì„¤ëª… ê°€ì ¸ì˜¤ê¸°
        dataset_properties = self.datahub_graph.get_aspect(
            urn, aspect_type=DatasetPropertiesClass
        )
        if dataset_properties:
            return dataset_properties.get("description", None)
        return None

    def get_column_names_and_descriptions(self, urn):
        # URNì— ëŒ€í•œ ì»¬ëŸ¼ ì´ë¦„ ë° ì„¤ëª… ê°€ì ¸ì˜¤ê¸°
        schema_metadata = self.datahub_graph.get_aspect(
            urn, aspect_type=SchemaMetadataClass
        )
        columns = []
        if schema_metadata:
            for field in schema_metadata.fields:

                # nativeDataTypeì´ ì—†ê±°ë‚˜ ë¹ˆ ë¬¸ìì—´ì¸ ê²½ìš° None ì²˜ë¦¬
                native_type = getattr(field, "nativeDataType", None)
                column_type = (
                    native_type if native_type and native_type.strip() else None
                )

                columns.append(
                    {
                        "column_name": field.fieldPath,
                        "column_description": field.description,
                        "column_type": column_type,
                    }
                )
        return columns

    def get_table_lineage(
        self,
        urn,
        counts=100,
        direction="DOWNSTREAM",
        degree_values=None,
    ):
        # URNì— ëŒ€í•œ DOWNSTREAM/UPSTREAM lineage entityë¥¼ counts ë§Œí¼ ê°€ì ¸ì˜¤ëŠ” í•¨ìˆ˜
        # degree_valuesì— ë”°ë¼ lineage depthê°€ ê²°ì •
        """
        Fetches downstream/upstream lineage entities for a given dataset URN using DataHub's GraphQL API.

        Args:
            urn (str): Dataset URN to fetch lineage for.
            count (int): Maximum number of entities to fetch (default=100).
            direction (str): DOWNSTREAM or UPSTREAM.
            degree_values (List[str]): Degree filter values like ["1", "2", "3+"]. Defaults to ["1", "2"].

        Returns:
            List[str, dict]: A list containing the dataset URN and its lineage result.
        """

        if degree_values is None:
            degree_values = ["1", "2"]

        graph = DataHubGraph(DatahubClientConfig(server=self.gms_server))

        query = """
            query scrollAcrossLineage($input: ScrollAcrossLineageInput!) {
            scrollAcrossLineage(input: $input) {
                searchResults {
                    degree
                    entity {
                        urn
                        type
                    }
                }
            }
        }
        """
        variables = {
            "input": {
                "query": "*",
                "urn": urn,
                "count": counts,
                "direction": direction,
                "orFilters": [
                    {
                        "and": [
                            {
                                "condition": "EQUAL",
                                "negated": "false",
                                "field": "degree",
                                "values": degree_values,
                            }
                        ]
                    }
                ],
            }
        }

        result = graph.execute_graphql(query=query, variables=variables)
        return urn, result

    def get_column_lineage(self, urn):
        # URNì— ëŒ€í•œ UPSTREAM lineageì˜ column sourceë¥¼ ê°€ì ¸ì˜¤ëŠ” í•¨ìˆ˜
        """
        Fetches fine-grained column-level lineage grouped by upstream datasets.

        Args:
            urn (str): Dataset URN to fetch lineage for.

        Returns:
            dict: {
                'downstream_dataset': str,
                'lineage_by_upstream_dataset': List[{
                    'upstream_dataset': str,
                    'columns': List[{'upstream_column': str, 'downstream_column': str}]
                }]
            }
        """

        # DataHub ì—°ê²° ë° lineage ê°€ì ¸ì˜¤ê¸°
        graph = DataHubGraph(DatahubClientConfig(server=self.gms_server))
        result = graph.get_aspect(entity_urn=urn, aspect_type=UpstreamLineageClass)

        # downstream dataset (URN í…Œì´ë¸”ëª…) íŒŒì‹±
        try:
            down_dataset = urn.split(",")[1]
            table_name = down_dataset.split(".")[1]

        except IndexError:
            # URNì´ ìœ íš¨í•˜ì§€ ì•ŠëŠ” ê²½ìš°
            print(f"[ERROR] Invalid URN format: {urn}")
            return {}

        # upstream_datasetë³„ë¡œ column lineage
        upstream_map = defaultdict(list)

        if not result:
            return {"downstream_dataset": table_name, "lineage_by_upstream_dataset": []}

        for fg in result.fineGrainedLineages or []:
            confidence_score = (
                fg.confidenceScore if fg.confidenceScore is not None else 1.0
            )
            for down in fg.downstreams:
                down_column = down.split(",")[-1].replace(")", "")
                for up in fg.upstreams:
                    up_dataset = up.split(",")[1]
                    up_dataset = up_dataset.split(".")[1]
                    up_column = up.split(",")[-1].replace(")", "")

                    upstream_map[up_dataset].append(
                        {
                            "upstream_column": up_column,
                            "downstream_column": down_column,
                            "confidence": confidence_score,
                        }
                    )

        # ìµœì¢… ê²°ê³¼ êµ¬ì¡° ìƒì„±
        parsed_lineage = {
            "downstream_dataset": table_name,
            "lineage_by_upstream_dataset": [],
        }

        for up_dataset, column_mappings in upstream_map.items():
            parsed_lineage["lineage_by_upstream_dataset"].append(
                {"upstream_dataset": up_dataset, "columns": column_mappings}
            )

        return parsed_lineage

    def min_degree_lineage(self, lineage_result):
        # lineage ì¤‘ ìµœì†Œ degreeë§Œ ê°€ì ¸ì˜¤ëŠ” í•¨ìˆ˜
        """
        Returns the minimum degree from the lineage result (fetched by get_table_lineage().)

        Args:
            lineage_result : (List[str, dict]): Result from get_table_lineage().

        Returns:
            dict : {table_name : minimum_degree}
        """

        table_degrees = {}

        urn, lineage_data = lineage_result

        for item in lineage_data["scrollAcrossLineage"]["searchResults"]:
            table = item["entity"]["urn"].split(",")[1]
            table_name = table.split(".")[1]
            degree = item["degree"]
            table_degrees[table_name] = min(
                degree, table_degrees.get(table_name, float("inf"))
            )

        return table_degrees

    def build_table_metadata(self, urn, max_degree=2, sort_by_degree=True):
        # í…Œì´ë¸” ë‹¨ìœ„ë¡œ í…Œì´ë¸” ì´ë¦„, ì„¤ëª…, ì»¬ëŸ¼, í…Œì´ë¸” ë³„ ë¦¬ë‹ˆì§€(downstream/upstream), ì»¬ëŸ¼ ë³„ ë¦¬ë‹ˆì§€(upstream)ì´ í¬í•¨ëœ ë©”íƒ€ë°ì´í„° ìƒì„± í•¨ìˆ˜
        """
        Builds table metadata including description, columns, and lineage info.

        Args:
            urn (str): Dataset URN
            max_degree (int): Max lineage depth to include (filtering)
            sort_by_degree (bool): Whether to sort downstream/upstream tables by degree

        Returns:
            dict: Table metadata
        """
        metadata = {
            "table_name": self.get_table_name(urn),
            "description": self.get_table_description(urn),
            "columns": self.get_column_names_and_descriptions(urn),
            "lineage": {},
        }

        def process_lineage(direction):
            # direction : DOWNSTREAM/UPSTREAM ë³„ë¡œ degreeê°€ ìµœì†Œì¸ lineageë¥¼ ê°€ì ¸ì˜¤ëŠ” í•¨ìˆ˜

            # í…Œì´ë¸” lineage ê°€ì ¸ì˜¤ê¸°
            lineage_result = self.get_table_lineage(urn, direction=direction)
            table_degrees = self.min_degree_lineage(lineage_result)
            current_table_name = metadata["table_name"]

            # degree í•„í„°ë§
            filtered_lineage = [
                {"table": table, "degree": degree}
                for table, degree in table_degrees.items()
                if degree <= max_degree and table != current_table_name
            ]

            # degree ê¸°ì¤€ ì •ë ¬
            if sort_by_degree:
                filtered_lineage.sort(key=lambda x: x["degree"])

            return filtered_lineage

        # DOWNSTREAM / UPSTREAM ë§í¬ ì¶”ê°€
        metadata["lineage"]["downstream"] = process_lineage("DOWNSTREAM")
        metadata["lineage"]["upstream"] = process_lineage("UPSTREAM")

        # ì»¬ëŸ¼ ë‹¨ìœ„ lineage ì¶”ê°€
        column_lineage = self.get_column_lineage(urn)
        metadata["lineage"]["upstream_columns"] = column_lineage.get(
            "lineage_by_upstream_dataset", []
        )

        return metadata

    def get_root_glossary_nodes(self):
        """
        DataHubì—ì„œ ë£¨íŠ¸ ìš©ì–´ì§‘ ë…¸ë“œë¥¼ ê°€ì ¸ì˜¤ëŠ” í•¨ìˆ˜

        Returns:
            dict: ë£¨íŠ¸ ìš©ì–´ì§‘ ë…¸ë“œ ì •ë³´
        """
        # GraphQL ìš”ì²­ ë³´ë‚´ê¸°
        headers = {"Content-Type": "application/json"}
        response = requests.post(
            f"{self.gms_server}/api/graphql",
            json={"query": ROOT_GLOSSARY_NODES_QUERY},
            headers=headers,
        )

        # ê²°ê³¼ ë°˜í™˜
        if response.status_code == 200:
            return response.json()
        else:
            return {
                "error": True,
                "status_code": response.status_code,
                "message": response.text,
            }

    def get_glossary_node_by_urn(self, urn):
        """
        DataHubì—ì„œ íŠ¹ì • URNì˜ ìš©ì–´ì§‘ ë…¸ë“œ ë° ê·¸ ìì‹ í•­ëª©ì„ ê°€ì ¸ì˜¤ëŠ” í•¨ìˆ˜

        Args:
            urn (str): ìš©ì–´ì§‘ ë…¸ë“œì˜ URN

        Returns:
            dict: ìš©ì–´ì§‘ ë…¸ë“œ ì •ë³´ì™€ ìì‹ í•­ëª©
        """
        # GraphQL ìš”ì²­ ë³´ë‚´ê¸°
        headers = {"Content-Type": "application/json"}
        response = requests.post(
            f"{self.gms_server}/api/graphql",
            json={"query": GLOSSARY_NODE_QUERY, "variables": {"urn": urn}},
            headers=headers,
        )

        # ê²°ê³¼ ë°˜í™˜
        if response.status_code == 200:
            return response.json()
        else:
            return {
                "error": True,
                "status_code": response.status_code,
                "message": response.text,
            }

    def get_node_basic_info(self, node, index):
        """
        ìš©ì–´ì§‘ ë…¸ë“œì˜ ê¸°ë³¸ ì •ë³´ë¥¼ ë”•ì…”ë„ˆë¦¬ë¡œ ë°˜í™˜í•˜ëŠ” í•¨ìˆ˜

        Args:
            node (dict): ìš©ì–´ì§‘ ë…¸ë“œ ì •ë³´
            index (int): ë…¸ë“œì˜ ì¸ë±ìŠ¤

        Returns:
            dict: ë…¸ë“œì˜ ê¸°ë³¸ ì •ë³´
        """
        result = {"index": index, "name": node["properties"]["name"]}

        if node["properties"] and node["properties"].get("description"):
            result["description"] = node["properties"]["description"]

        # ìì‹ ë…¸ë“œ/ìš©ì–´ ê´€ê³„ ì •ë³´ ìˆ˜ ì¶”ê°€
        if "children" in node and node["children"]["total"] > 0:
            result["child_count"] = node["children"]["total"]

        return result

    def get_child_entity_info(self, entity, index):
        """
        ìì‹ ì—”í‹°í‹°(ìš©ì–´ ë˜ëŠ” ë…¸ë“œ)ì˜ ì •ë³´ë¥¼ ë”•ì…”ë„ˆë¦¬ë¡œ ë°˜í™˜í•˜ëŠ” í•¨ìˆ˜

        Args:
            entity (dict): ìì‹ ì—”í‹°í‹° ì •ë³´
            index (int): ì—”í‹°í‹°ì˜ ì¸ë±ìŠ¤

        Returns:
            dict: ì—”í‹°í‹° ì •ë³´
        """
        entity_type = entity["type"]
        result = {"index": index, "type": entity_type}

        if entity_type == "GLOSSARY_TERM":
            if "properties" in entity and entity["properties"]:
                result["name"] = entity["properties"].get("name", "N/A")

                if (
                    "description" in entity["properties"]
                    and entity["properties"]["description"]
                ):
                    result["description"] = entity["properties"]["description"]

        elif entity_type == "GLOSSARY_NODE":
            if "properties" in entity and entity["properties"]:
                result["name"] = entity["properties"].get("name", "N/A")

        return result

    def process_node_details(self, node):
        """
        ë…¸ë“œì˜ ìƒì„¸ ì •ë³´ë¥¼ ì²˜ë¦¬í•˜ê³  ë”•ì…”ë„ˆë¦¬ë¡œ ë°˜í™˜í•˜ëŠ” í•¨ìˆ˜

        Args:
            node (dict): ìš©ì–´ì§‘ ë…¸ë“œ ì •ë³´

        Returns:
            dict: ë…¸ë“œì˜ ìƒì„¸ ì •ë³´
        """
        node_urn = node["urn"]
        detailed_node = self.get_glossary_node_by_urn(node_urn)

        result = {"name": node["properties"]["name"], "children": []}

        if (
            detailed_node
            and "data" in detailed_node
            and "glossaryNode" in detailed_node["data"]
        ):
            node_detail = detailed_node["data"]["glossaryNode"]

            # ìì‹ í•­ëª© ì •ë³´ ì¶”ì¶œ
            if "children" in node_detail and node_detail["children"]["total"] > 0:
                relationships = node_detail["children"]["relationships"]

                for j, rel in enumerate(relationships, 1):
                    entity = rel["entity"]
                    result["children"].append(self.get_child_entity_info(entity, j))

        return result

    def process_glossary_nodes(self, result):
        """
        ìš©ì–´ì§‘ ë…¸ë“œ ê²°ê³¼ë¥¼ ì²˜ë¦¬í•˜ê³  ë”•ì…”ë„ˆë¦¬ë¡œ ë°˜í™˜í•˜ëŠ” í•¨ìˆ˜

        Args:
            result (dict): API ì‘ë‹µ ê²°ê³¼

        Returns:
            dict: ì²˜ë¦¬ëœ ìš©ì–´ì§‘ ë…¸ë“œ ë°ì´í„°
        """
        if "error" in result:
            return result

        processed_result = {"total_nodes": 0, "nodes": []}

        # ë…¸ë“œ ëª©ë¡ ì¶”ì¶œ
        nodes = result["data"]["getRootGlossaryNodes"]["nodes"]
        processed_result["total_nodes"] = len(nodes)

        for i, node in enumerate(nodes, 1):
            node_info = self.get_node_basic_info(node, i)

            # ìì‹ ë…¸ë“œê°€ ìˆìœ¼ë©´ ìƒì„¸ ì •ë³´ ì²˜ë¦¬
            if "children" in node and node["children"]["total"] > 0:
                node_details = self.process_node_details(node)
                node_info["details"] = node_details

            processed_result["nodes"].append(node_info)

        return processed_result

    def get_glossary_data(self):
        """
        DataHubì—ì„œ ì „ì²´ ìš©ì–´ì§‘ ë°ì´í„°ë¥¼ ê°€ì ¸ì™€ ì²˜ë¦¬í•˜ëŠ” í•¨ìˆ˜

        Returns:
            dict: ì²˜ë¦¬ëœ ìš©ì–´ì§‘ ë°ì´í„°
        """
        # DataHub ì„œë²„ì— ì—°ê²°í•˜ì—¬ ìš©ì–´ì§‘ ë…¸ë“œ ê°€ì ¸ì˜¤ê¸°
        result = self.get_root_glossary_nodes()

        # ê²°ê³¼ ì²˜ë¦¬
        if result:
            try:
                return self.process_glossary_nodes(result)
            except KeyError as e:
                return {"error": True, "message": f"ê²°ê³¼ êµ¬ì¡° íŒŒì‹± ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}"}
        else:
            return {"error": True, "message": "ìš©ì–´ì§‘ ë…¸ë“œë¥¼ ê°€ì ¸ì˜¤ì§€ ëª»í–ˆìŠµë‹ˆë‹¤."}

    def get_queries(self, start=0, count=10, query="*", filters=None):
        """
        DataHubì—ì„œ ì¿¼ë¦¬ ëª©ë¡ì„ ê°€ì ¸ì˜¤ëŠ” í•¨ìˆ˜

        Args:
            start (int): ì‹œì‘ ì¸ë±ìŠ¤ (ê¸°ë³¸ê°’=0)
            count (int): ë°˜í™˜í•  ì¿¼ë¦¬ ìˆ˜ (ê¸°ë³¸ê°’=10)
            query (str): í•„í„°ë§ì— ì‚¬ìš©í•  ì¿¼ë¦¬ ë¬¸ìì—´ (ê¸°ë³¸ê°’="*")
            filters (list): ì¶”ê°€ í•„í„° (ê¸°ë³¸ê°’=None)

        Returns:
            dict: ì¿¼ë¦¬ ëª©ë¡ ì •ë³´
        """
        # GraphQL ìš”ì²­ìš© ì…ë ¥ ë³€ìˆ˜ ì¤€ë¹„
        input_params = {"start": start, "count": count, "query": query}

        if filters:
            input_params["filters"] = filters

        variables = {"input": input_params}

        # GraphQL ìš”ì²­ ë³´ë‚´ê¸°
        headers = {"Content-Type": "application/json"}
        response = requests.post(
            f"{self.gms_server}/api/graphql",
            json={"query": LIST_QUERIES_QUERY, "variables": variables},
            headers=headers,
        )

        # ê²°ê³¼ ë°˜í™˜
        if response.status_code == 200:
            return response.json()
        else:
            return {
                "error": True,
                "status_code": response.status_code,
                "message": response.text,
            }

    def process_queries(self, result):
        """
        ì¿¼ë¦¬ ëª©ë¡ ê²°ê³¼ë¥¼ ì²˜ë¦¬í•˜ê³  ê°„ì†Œí™”ëœ í˜•íƒœë¡œ ë°˜í™˜í•˜ëŠ” í•¨ìˆ˜

        Args:
            result (dict): API ì‘ë‹µ ê²°ê³¼

        Returns:
            dict: ì²˜ë¦¬ëœ ì¿¼ë¦¬ ëª©ë¡ ë°ì´í„° (urn, name, description, statementë§Œ í¬í•¨)
        """
        if "error" in result:
            return result

        processed_result = {"total_queries": 0, "count": 0, "start": 0, "queries": []}

        if "data" in result and "listQueries" in result["data"]:
            list_queries = result["data"]["listQueries"]
            processed_result["total_queries"] = list_queries.get("total", 0)
            processed_result["count"] = list_queries.get("count", 0)
            processed_result["start"] = list_queries.get("start", 0)

            for query in list_queries.get("queries", []):
                query_info = {"urn": query.get("urn")}

                props = query.get("properties", {})
                query_info["name"] = props.get("name")
                query_info["description"] = props.get("description")
                query_info["statement"] = props.get("statement", {}).get("value")

                processed_result["queries"].append(query_info)

        return processed_result

    def get_query_data(self, start=0, count=10, query="*", filters=None):
        """
        DataHubì—ì„œ ì¿¼ë¦¬ ëª©ë¡ì„ ê°€ì ¸ì™€ ì²˜ë¦¬í•˜ëŠ” í•¨ìˆ˜

        Args:
            start (int): ì‹œì‘ ì¸ë±ìŠ¤ (ê¸°ë³¸ê°’=0)
            count (int): ë°˜í™˜í•  ì¿¼ë¦¬ ìˆ˜ (ê¸°ë³¸ê°’=10)
            query (str): í•„í„°ë§ì— ì‚¬ìš©í•  ì¿¼ë¦¬ ë¬¸ìì—´ (ê¸°ë³¸ê°’="*")
            filters (list): ì¶”ê°€ í•„í„° (ê¸°ë³¸ê°’=None)

        Returns:
            dict: ì²˜ë¦¬ëœ ì¿¼ë¦¬ ëª©ë¡ ë°ì´í„°
        """
        # DataHub ì„œë²„ì— ì—°ê²°í•˜ì—¬ ì¿¼ë¦¬ ëª©ë¡ ê°€ì ¸ì˜¤ê¸°
        result = self.get_queries(start, count, query, filters)

        # ê²°ê³¼ ì²˜ë¦¬
        if result:
            try:
                return self.process_queries(result)
            except KeyError as e:
                return {"error": True, "message": f"ê²°ê³¼ êµ¬ì¡° íŒŒì‹± ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}"}
        else:
            return {"error": True, "message": "ì¿¼ë¦¬ ëª©ë¡ì„ ê°€ì ¸ì˜¤ì§€ ëª»í–ˆìŠµë‹ˆë‹¤."}

    def get_urn_info(self, urn):
        """
        íŠ¹ì • URNì— ëŒ€í•œ ëª¨ë“  ê´€ë ¨ ì •ë³´ë¥¼ ê°€ì ¸ì˜¤ëŠ” í•¨ìˆ˜

        Args:
            urn (str): ì¡°íšŒí•  ë°ì´í„°ì…‹ URN

        Returns:
            dict: URNì— ëŒ€í•œ ì „ì²´ ë©”íƒ€ë°ì´í„° ì •ë³´
        """
        print(f"\n=== URN ì •ë³´ ì¡°íšŒ: {urn} ===\n")

        try:
            # ê¸°ë³¸ í…Œì´ë¸” ë©”íƒ€ë°ì´í„° ê°€ì ¸ì˜¤ê¸°
            metadata = self.build_table_metadata(urn)

            # ê²°ê³¼ ì¶œë ¥
            self._print_urn_details(metadata)

            return metadata

        except Exception as e:
            error_msg = f"URN ì •ë³´ ì¡°íšŒ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}"
            print(error_msg)
            return {"error": True, "message": error_msg}

    def _print_urn_details(self, metadata):
        """URN ë©”íƒ€ë°ì´í„°ë¥¼ ë³´ê¸° ì¢‹ê²Œ ì¶œë ¥í•˜ëŠ” ë‚´ë¶€ í•¨ìˆ˜"""

        # í…Œì´ë¸” ê¸°ë³¸ ì •ë³´
        print("ğŸ“‹ í…Œì´ë¸” ì •ë³´:")
        print(f"  ì´ë¦„: {metadata.get('table_name', 'N/A')}")
        print(f"  ì„¤ëª…: {metadata.get('description', 'N/A')}\n")

        # ì»¬ëŸ¼ ì •ë³´
        columns = metadata.get("columns", [])
        if columns:
            print(f"ğŸ“Š ì»¬ëŸ¼ ì •ë³´ ({len(columns)}ê°œ):")
            for i, col in enumerate(columns, 1):
                print(f"  {i}. {col['column_name']} ({col.get('column_type', 'N/A')})")
                if col.get("column_description"):
                    print(f"     â†’ {col['column_description']}")
            print()

        # ë¦¬ë‹ˆì§€ ì •ë³´
        lineage = metadata.get("lineage", {})

        # Downstream í…Œì´ë¸”
        downstream = lineage.get("downstream", [])
        if downstream:
            print(f"â¬‡ï¸ Downstream í…Œì´ë¸” ({len(downstream)}ê°œ):")
            for table in downstream:
                print(f"  - {table['table']} (degree: {table['degree']})")
            print()

        # Upstream í…Œì´ë¸”
        upstream = lineage.get("upstream", [])
        if upstream:
            print(f"â¬†ï¸ Upstream í…Œì´ë¸” ({len(upstream)}ê°œ):")
            for table in upstream:
                print(f"  - {table['table']} (degree: {table['degree']})")
            print()

        # ì»¬ëŸ¼ ë ˆë²¨ ë¦¬ë‹ˆì§€
        upstream_columns = lineage.get("upstream_columns", [])
        if upstream_columns:
            print("ğŸ”— ì»¬ëŸ¼ ë ˆë²¨ ë¦¬ë‹ˆì§€:")
            for upstream_dataset in upstream_columns:
                dataset_name = upstream_dataset["upstream_dataset"]
                columns = upstream_dataset["columns"]
                print(f"  ğŸ“‹ {dataset_name}:")
                for col in columns:
                    confidence = col.get("confidence", 1.0)
                    print(
                        f"    {col['upstream_column']} â†’ {col['downstream_column']} (ì‹ ë¢°ë„: {confidence})"
                    )
            print()

    def get_queries_by_urn(self, dataset_urn):
        """
        íŠ¹ì • ë°ì´í„°ì…‹ URNê³¼ ì—°ê´€ëœ ì¿¼ë¦¬ë“¤ì„ ì¡°íšŒí•˜ëŠ” í•¨ìˆ˜

        ì „ì²´ ì¿¼ë¦¬ë¥¼ ê°€ì ¸ì˜¨ í›„ í´ë¼ì´ì–¸íŠ¸ ì‚¬ì´ë“œì—ì„œ í•„í„°ë§í•˜ëŠ” ë°©ì‹ ì‚¬ìš©

        Args:
            dataset_urn (str): ë°ì´í„°ì…‹ URN

        Returns:
            dict: ì—°ê´€ëœ ì¿¼ë¦¬ ëª©ë¡
        """
        # ë¨¼ì € ì „ì²´ ì¿¼ë¦¬ ëª©ë¡ì„ ê°€ì ¸ì˜´
        input_params = {"start": 0, "count": 1000, "query": "*"}  # ì¶©ë¶„íˆ í° ìˆ˜ë¡œ ì„¤ì •

        variables = {"input": input_params}

        headers = {"Content-Type": "application/json"}
        response = requests.post(
            f"{self.gms_server}/api/graphql",
            json={"query": QUERIES_BY_URN_QUERY, "variables": variables},
            headers=headers,
        )

        if response.status_code == 200:
            result = response.json()
            if "data" in result and "listQueries" in result["data"]:
                # í´ë¼ì´ì–¸íŠ¸ ì‚¬ì´ë“œì—ì„œ íŠ¹ì • URNê³¼ ì—°ê´€ëœ ì¿¼ë¦¬ë§Œ í•„í„°ë§
                all_queries = result["data"]["listQueries"]["queries"]
                filtered_queries = []

                for query in all_queries:
                    subjects = query.get("subjects", [])
                    for subject in subjects:
                        if subject.get("dataset", {}).get("urn") == dataset_urn:
                            filtered_queries.append(query)
                            break

                # í•„í„°ë§ëœ ê²°ê³¼ë¡œ ì‘ë‹µ êµ¬ì¡° ì¬êµ¬ì„±
                result["data"]["listQueries"]["queries"] = filtered_queries
                result["data"]["listQueries"]["count"] = len(filtered_queries)

            return result
        else:
            return {
                "error": True,
                "status_code": response.status_code,
                "message": response.text,
            }

    def get_glossary_terms_by_urn(self, dataset_urn):
        """
        íŠ¹ì • ë°ì´í„°ì…‹ URNì˜ glossary termsë¥¼ ì¡°íšŒí•˜ëŠ” í•¨ìˆ˜

        Args:
            dataset_urn (str): ë°ì´í„°ì…‹ URN

        Returns:
            dict: glossary terms ì •ë³´
        """
        variables = {"urn": dataset_urn}

        headers = {"Content-Type": "application/json"}
        response = requests.post(
            f"{self.gms_server}/api/graphql",
            json={"query": GLOSSARY_TERMS_BY_URN_QUERY, "variables": variables},
            headers=headers,
        )

        if response.status_code == 200:
            return response.json()
        else:
            return {
                "error": True,
                "status_code": response.status_code,
                "message": response.text,
            }


if __name__ == "__main__":
    fetcher = DatahubMetadataFetcher()

    print(
        fetcher.get_queries_by_urn(
            "urn:li:dataset:(urn:li:dataPlatform:dbt,small_bank_1.small_bank_1.ACCOUNTS,PROD)"
        )
    )
    print(
        fetcher.get_glossary_terms_by_urn(
            "urn:li:dataset:(urn:li:dataPlatform:dbt,small_bank_1.small_bank_1.ACCOUNTS,PROD)"
        )
    )
