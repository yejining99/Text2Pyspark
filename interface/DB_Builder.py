"""
FAISS Vector DB ê´€ë¦¬ ë° í™•ì¸ í˜ì´ì§€

FAISS ë°ì´í„°ë² ì´ìŠ¤ì˜ ìƒíƒœë¥¼ í™•ì¸í•˜ê³  ê´€ë¦¬í•  ìˆ˜ ìˆëŠ” ê¸°ëŠ¥ì„ ì œê³µí•©ë‹ˆë‹¤.
- ë²¡í„° DB ìƒíƒœ í™•ì¸
- ì €ì¥ëœ í…Œì´ë¸” ì •ë³´ ì¡°íšŒ
- ê²€ìƒ‰ í…ŒìŠ¤íŠ¸
- ìƒˆë¡œìš´ í…Œì´ë¸” ì •ë³´ ì¶”ê°€
"""

import streamlit as st
import os
import json
import pandas as pd
from datetime import datetime
from typing import Dict, List, Optional
import traceback

# LangSQL ëª¨ë“ˆë“¤
from llm_utils.vectordb import get_vector_db
from llm_utils.retrieval import search_tables
from llm_utils.llm import get_embeddings

# í˜ì´ì§€ ì„¤ì •
st.set_page_config(
    page_title="DB Builder", 
    page_icon="ğŸ—„ï¸", 
    layout="wide"
)

st.title("ğŸ—„ï¸ FAISS Vector DB ê´€ë¦¬ì")
st.markdown("---")

def get_vectordb_info():
    """ë²¡í„° DB ì •ë³´ë¥¼ ê°€ì ¸ì˜µë‹ˆë‹¤."""
    try:
        # ê¸°ë³¸ ê²½ë¡œ
        vectordb_path = os.path.join(os.getcwd(), "table_info_db")
        
        info = {
            "path": vectordb_path,
            "exists": os.path.exists(vectordb_path),
            "faiss_file": os.path.join(vectordb_path, "index.faiss"),
            "pkl_file": os.path.join(vectordb_path, "index.pkl"),
            "faiss_exists": os.path.exists(os.path.join(vectordb_path, "index.faiss")),
            "pkl_exists": os.path.exists(os.path.join(vectordb_path, "index.pkl")),
        }
        
        # íŒŒì¼ í¬ê¸° ì •ë³´
        if info["faiss_exists"]:
            info["faiss_size"] = os.path.getsize(info["faiss_file"]) / 1024  # KB
            info["faiss_modified"] = datetime.fromtimestamp(
                os.path.getmtime(info["faiss_file"])
            )
            
        if info["pkl_exists"]:
            info["pkl_size"] = os.path.getsize(info["pkl_file"]) / 1024  # KB
            info["pkl_modified"] = datetime.fromtimestamp(
                os.path.getmtime(info["pkl_file"])
            )
            
        return info
    except Exception as e:
        st.error(f"ë²¡í„° DB ì •ë³´ ì¡°íšŒ ì¤‘ ì˜¤ë¥˜: {e}")
        return None

def test_vectordb_connection():
    """ë²¡í„° DB ì—°ê²°ì„ í…ŒìŠ¤íŠ¸í•©ë‹ˆë‹¤."""
    try:
        db = get_vector_db()
        # ê°„ë‹¨í•œ ê²€ìƒ‰ìœ¼ë¡œ í…ŒìŠ¤íŠ¸
        docs = db.similarity_search("í…ŒìŠ¤íŠ¸", k=1)
        return True, len(docs), db
    except Exception as e:
        return False, str(e), None

def extract_all_documents(db):
    """ë²¡í„° DBì˜ ëª¨ë“  ë¬¸ì„œë¥¼ ì¶”ì¶œí•©ë‹ˆë‹¤."""
    try:
        # FAISSì—ì„œ ëª¨ë“  ë¬¸ì„œ ê°€ì ¸ì˜¤ê¸°
        all_docs = []
        
        # docstoreì—ì„œ ì§ì ‘ ê°€ì ¸ì˜¤ê¸°
        if hasattr(db, 'docstore') and hasattr(db.docstore, '_dict'):
            for doc_id, doc in db.docstore._dict.items():
                all_docs.append({
                    "id": doc_id,
                    "content": doc.page_content,
                    "metadata": doc.metadata
                })
        
        return all_docs
    except Exception as e:
        st.error(f"ë¬¸ì„œ ì¶”ì¶œ ì¤‘ ì˜¤ë¥˜: {e}")
        return []

def parse_table_info(content: str) -> Dict:
    """í…Œì´ë¸” ì •ë³´ í…ìŠ¤íŠ¸ë¥¼ íŒŒì‹±í•©ë‹ˆë‹¤."""
    try:
        lines = content.split("\n")
        
        if ": " not in lines[0]:
            return {"error": "ì˜ëª»ëœ í˜•ì‹"}
            
        table_name, table_desc = lines[0].split(": ", 1)
        
        columns = {}
        current_section = None
        
        for line in lines[1:]:
            line = line.strip()
            if line == "Columns:":
                current_section = "columns"
                continue
                
            if current_section == "columns" and ": " in line:
                col_name, col_desc = line.split(": ", 1)
                columns[col_name.strip()] = col_desc.strip()
        
        return {
            "table_name": table_name,
            "table_description": table_desc.strip(),
            "columns": columns,
            "column_count": len(columns)
        }
    except Exception as e:
        return {"error": str(e)}

# ë©”ì¸ ë ˆì´ì•„ì›ƒ
col1, col2 = st.columns([1, 2])

with col1:
    st.subheader("ğŸ“Š DB ìƒíƒœ ì •ë³´")
    
    # ë²¡í„° DB ì •ë³´ í‘œì‹œ
    db_info = get_vectordb_info()
    
    if db_info:
        st.markdown("**ğŸ“‚ íŒŒì¼ ê²½ë¡œ:**")
        st.code(db_info["path"])
        
        # ìƒíƒœ í‘œì‹œ
        if db_info["exists"]:
            st.success("âœ… ë””ë ‰í† ë¦¬ ì¡´ì¬")
        else:
            st.error("âŒ ë””ë ‰í† ë¦¬ ì—†ìŒ")
            
        # íŒŒì¼ ìƒíƒœ
        col_a, col_b = st.columns(2)
        with col_a:
            if db_info["faiss_exists"]:
                st.success("âœ… FAISS íŒŒì¼")
                st.write(f"í¬ê¸°: {db_info['faiss_size']:.1f} KB")
                st.write(f"ìˆ˜ì •: {db_info['faiss_modified'].strftime('%Y-%m-%d %H:%M')}")
            else:
                st.error("âŒ FAISS íŒŒì¼ ì—†ìŒ")
                
        with col_b:
            if db_info["pkl_exists"]:
                st.success("âœ… PKL íŒŒì¼")
                st.write(f"í¬ê¸°: {db_info['pkl_size']:.1f} KB")
                st.write(f"ìˆ˜ì •: {db_info['pkl_modified'].strftime('%Y-%m-%d %H:%M')}")
            else:
                st.error("âŒ PKL íŒŒì¼ ì—†ìŒ")
    
    st.markdown("---")
    
    # ì—°ê²° í…ŒìŠ¤íŠ¸
    st.subheader("ğŸ”Œ ì—°ê²° í…ŒìŠ¤íŠ¸")
    
    if st.button("DB ì—°ê²° í…ŒìŠ¤íŠ¸"):
        with st.spinner("ì—°ê²° í…ŒìŠ¤íŠ¸ ì¤‘..."):
            success, result, db = test_vectordb_connection()
            
            if success:
                st.success(f"âœ… ì—°ê²° ì„±ê³µ! ({result}ê°œ ë¬¸ì„œ í™•ì¸)")
                st.session_state["db_connected"] = True
                st.session_state["vector_db"] = db
            else:
                st.error(f"âŒ ì—°ê²° ì‹¤íŒ¨: {result}")
                st.session_state["db_connected"] = False

with col2:
    st.subheader("ğŸ” DB ë‚´ìš© íƒìƒ‰")
    
    # íƒ­ ìƒì„±
    tab1, tab2, tab3 = st.tabs(["ğŸ“‹ í…Œì´ë¸” ëª©ë¡", "ğŸ” ê²€ìƒ‰ í…ŒìŠ¤íŠ¸", "â• ìƒˆ í…Œì´ë¸” ì¶”ê°€"])
    
    with tab1:
        if st.session_state.get("db_connected", False):
            db = st.session_state.get("vector_db")
            
            if st.button("ğŸ“¥ ëª¨ë“  í…Œì´ë¸” ì •ë³´ ë¶ˆëŸ¬ì˜¤ê¸°"):
                with st.spinner("í…Œì´ë¸” ì •ë³´ ë¡œë”© ì¤‘..."):
                    all_docs = extract_all_documents(db)
                    
                    if all_docs:
                        st.success(f"ì´ {len(all_docs)}ê°œì˜ í…Œì´ë¸” ì •ë³´ë¥¼ ì°¾ì•˜ìŠµë‹ˆë‹¤.")
                        
                        # í…Œì´ë¸” ì •ë³´ íŒŒì‹± ë° í‘œì‹œ
                        table_data = []
                        
                        for doc in all_docs:
                            parsed = parse_table_info(doc["content"])
                            if "error" not in parsed:
                                table_data.append({
                                    "í…Œì´ë¸”ëª…": parsed["table_name"],
                                    "ì„¤ëª…": parsed["table_description"][:50] + "..." if len(parsed["table_description"]) > 50 else parsed["table_description"],
                                    "ì»¬ëŸ¼ìˆ˜": parsed["column_count"],
                                    "ID": doc["id"]
                                })
                        
                        if table_data:
                            df = pd.DataFrame(table_data)
                            st.dataframe(df, use_container_width=True)
                            
                            # ì„ íƒí•œ í…Œì´ë¸”ì˜ ìƒì„¸ ì •ë³´
                            selected_table = st.selectbox(
                                "ìƒì„¸ ì •ë³´ë¥¼ ë³¼ í…Œì´ë¸” ì„ íƒ:",
                                options=[t["í…Œì´ë¸”ëª…"] for t in table_data],
                                key="selected_table"
                            )
                            
                            if selected_table:
                                # ì„ íƒëœ í…Œì´ë¸”ì˜ ì „ì²´ ì •ë³´ í‘œì‹œ
                                selected_doc = None
                                for doc in all_docs:
                                    parsed = parse_table_info(doc["content"])
                                    if "error" not in parsed and parsed["table_name"] == selected_table:
                                        selected_doc = doc
                                        break
                                
                                if selected_doc:
                                    st.markdown(f"### ğŸ“‹ {selected_table} ìƒì„¸ ì •ë³´")
                                    
                                    parsed = parse_table_info(selected_doc["content"])
                                    st.write(f"**ì„¤ëª…:** {parsed['table_description']}")
                                    
                                    if parsed["columns"]:
                                        st.write("**ì»¬ëŸ¼ ì •ë³´:**")
                                        columns_df = pd.DataFrame([
                                            {"ì»¬ëŸ¼ëª…": col, "ì„¤ëª…": desc}
                                            for col, desc in parsed["columns"].items()
                                        ])
                                        st.dataframe(columns_df, use_container_width=True)
                                    
                                    # ì›ë³¸ í…ìŠ¤íŠ¸
                                    with st.expander("ğŸ“„ ì›ë³¸ í…ìŠ¤íŠ¸"):
                                        st.code(selected_doc["content"])
                        else:
                            st.warning("íŒŒì‹± ê°€ëŠ¥í•œ í…Œì´ë¸” ì •ë³´ê°€ ì—†ìŠµë‹ˆë‹¤.")
                    else:
                        st.warning("ì €ì¥ëœ í…Œì´ë¸” ì •ë³´ê°€ ì—†ìŠµë‹ˆë‹¤.")
        else:
            st.info("ë¨¼ì € DB ì—°ê²° í…ŒìŠ¤íŠ¸ë¥¼ ì‹¤í–‰í•´ì£¼ì„¸ìš”.")
    
    with tab2:
        st.markdown("### ğŸ” ê²€ìƒ‰ ê¸°ëŠ¥ í…ŒìŠ¤íŠ¸")
        
        search_query = st.text_input(
            "ê²€ìƒ‰í•  í‚¤ì›Œë“œë¥¼ ì…ë ¥í•˜ì„¸ìš”:",
            value="ë‚œì²­ í™˜ì",
            key="search_query"
        )
        
        col_search1, col_search2 = st.columns(2)
        with col_search1:
            retriever_type = st.selectbox(
                "ê²€ìƒ‰ ë°©ì‹:",
                ["ê¸°ë³¸", "Reranker"],
                key="search_retriever"
            )
        with col_search2:
            top_k = st.slider("ê²°ê³¼ ê°œìˆ˜:", 1, 10, 5, key="search_top_k")
        
        if st.button("ğŸ” ê²€ìƒ‰ ì‹¤í–‰"):
            if search_query.strip():
                with st.spinner("ê²€ìƒ‰ ì¤‘..."):
                    try:
                        results = search_tables(
                            query=search_query,
                            retriever_name=retriever_type,
                            top_n=top_k,
                            device="cpu"
                        )
                        
                        if results:
                            st.success(f"âœ… {len(results)}ê°œì˜ í…Œì´ë¸”ì„ ì°¾ì•˜ìŠµë‹ˆë‹¤.")
                            
                            for i, (table_name, table_info) in enumerate(results.items(), 1):
                                with st.expander(f"{i}. {table_name} (ìœ ì‚¬ë„: {table_info.get('score', 'N/A')})"):
                                    st.write(f"**ì„¤ëª…:** {table_info.get('table_description', 'N/A')}")
                                    
                                    # ì»¬ëŸ¼ ì •ë³´ í‘œì‹œ
                                    columns = {k: v for k, v in table_info.items() 
                                             if k not in ['table_description', 'score', 'rank']}
                                    if columns:
                                        st.write("**ì£¼ìš” ì»¬ëŸ¼:**")
                                        for col, desc in list(columns.items())[:5]:  # ìƒìœ„ 5ê°œë§Œ
                                            st.write(f"- **{col}**: {desc}")
                        else:
                            st.warning("ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.")
                            
                    except Exception as e:
                        st.error(f"ê²€ìƒ‰ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
                        with st.expander("ì˜¤ë¥˜ ìƒì„¸"):
                            st.code(traceback.format_exc())
            else:
                st.warning("ê²€ìƒ‰ì–´ë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.")
    
    with tab3:
        st.markdown("### â• ìƒˆë¡œìš´ í…Œì´ë¸” ì •ë³´ ì¶”ê°€")
        st.info("í˜„ì¬ëŠ” ì½ê¸° ì „ìš©ì…ë‹ˆë‹¤. ìƒˆë¡œìš´ í…Œì´ë¸” ì •ë³´ë¥¼ ì¶”ê°€í•˜ë ¤ë©´ table_catalog.csvë¥¼ ìˆ˜ì •í•œ í›„ create_faiss.pyë¥¼ ì‹¤í–‰í•˜ì„¸ìš”.")
        
        with st.expander("ğŸ“ í…Œì´ë¸” ì •ë³´ í˜•ì‹ ì˜ˆì‹œ"):
            st.code("""
í…Œì´ë¸”ëª…: ì„¤ëª…
Columns:
ì»¬ëŸ¼ëª…1: ì»¬ëŸ¼ ì„¤ëª…1
ì»¬ëŸ¼ëª…2: ì»¬ëŸ¼ ì„¤ëª…2
            """)
        
        st.markdown("**ğŸ’¡ ì¶”ê°€ ë°©ë²•:**")
        st.markdown("""
1. `table_catalog.csv` íŒŒì¼ì— ìƒˆë¡œìš´ í…Œì´ë¸”/ì»¬ëŸ¼ ì •ë³´ ì¶”ê°€
2. `create_faiss.py` ìŠ¤í¬ë¦½íŠ¸ ì‹¤í–‰í•˜ì—¬ ë²¡í„° DB ì¬ìƒì„±
3. Streamlit ì•± ì¬ì‹œì‘
        """)

# ì‚¬ì´ë“œë°”ì— ì¶”ê°€ ì •ë³´
st.sidebar.markdown("### ğŸ“– ì‚¬ìš© ê°€ì´ë“œ")
st.sidebar.markdown("""
**DB Builderì˜ ì£¼ìš” ê¸°ëŠ¥:**

1. **DB ìƒíƒœ í™•ì¸**: FAISS ì¸ë±ìŠ¤ íŒŒì¼ ìƒíƒœ ëª¨ë‹ˆí„°ë§
2. **í…Œì´ë¸” íƒìƒ‰**: ì €ì¥ëœ ëª¨ë“  í…Œì´ë¸” ì •ë³´ ì¡°íšŒ
3. **ê²€ìƒ‰ í…ŒìŠ¤íŠ¸**: ë²¡í„° ê²€ìƒ‰ ê¸°ëŠ¥ í…ŒìŠ¤íŠ¸
4. **ì •ë³´ ê´€ë¦¬**: í…Œì´ë¸” ë©”íƒ€ë°ì´í„° ê´€ë¦¬

**ì£¼ì˜ì‚¬í•­:**
- ìˆ˜ì • ì‘ì—…ì€ ì‹ ì¤‘í•˜ê²Œ ì§„í–‰í•˜ì„¸ìš”
- ë°±ì—…ì„ ê¶Œì¥í•©ë‹ˆë‹¤
""")

# í™˜ê²½ ì •ë³´
with st.sidebar.expander("ğŸ”§ í™˜ê²½ ì •ë³´"):
    st.write("**ì„ë² ë”© ëª¨ë¸ ì •ë³´:**")
    try:
        embeddings = get_embeddings()
        st.write(f"- ëª¨ë¸: {getattr(embeddings, 'model', 'Unknown')}")
        st.write(f"- ì œê³µì: {type(embeddings).__name__}")
    except Exception as e:
        st.write(f"- ì˜¤ë¥˜: {e}")
